---
permalink: /
title: "Story about Where I Started My Journey"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Previously, I collaborated on a UW iSchool capstone project, EVAN9000, with team InfVision. The project leverages open-source large language models (LLMs) to democratize access to advanced digital tools, specifically targeting underprivileged organizations and small businesses. It aims to dismantle technological barriers that often exclude smaller entities from benefiting from AI advancements monopolized by larger enterprises. By focusing on the scalability of open-source models and local customization, EVAN9000 offers a cost-effective way to enhance operational efficiency, enabling these organizations to compete more effectively and innovate within their sectors.

This project ignited my passion for research, inspiring me to delve deeper into the possibilities of using AI to promote inclusivity and digital equity. Witnessing firsthand how technological gaps can limit innovation for smaller entities drove me to explore solutions that bridge these divides. Working on EVAN9000 made me realize the potential of open-source LLMs to democratize digital access and empower underprivileged organizations. This experience solidified my desire to contribute to research initiatives focused on scalable AI solutions, fostering equitable access and sustainable growth for all communities.


Getting started Research
======
In my overconfidence research project, I focused on exploring the psychological and cognitive aspects of overconfidence in humans and comparing these with similar patterns observed in AI systems. The goal was to examine how individuals and AI models assess their knowledge and decision-making accuracy, especially in contexts involving complex problem-solving or ambiguous information.

Under the guidance of Professor Howe, this project involved designing and conducting a series of experiments to study human confidence levels in relation to task difficulty. We measured participantsâ€™ self-assessments of their performance and compared them with their actual accuracy to quantify overconfidence biases. My analysis revealed notable trends, such as the tendency to overestimate accuracy in easier tasks and underestimate it in more challenging ones.

Building on these insights, I extended the research to large language models (LLMs) to evaluate their confidence calibration. By incorporating varying types of prompts, expertise levels, and task difficulties, I observed patterns in LLM confidence behavior that both mimicked and diverged from human tendencies. For instance, while LLMs displayed consistent confidence in familiar domains, their calibration varied significantly when dealing with novel or ambiguous tasks.

This comparative analysis of humans and AI underscored the importance of developing better calibration techniques to improve the reliability and trustworthiness of AI systems in decision-making scenarios. Moreover, it highlighted the need for an ethical approach in designing AI models, ensuring they are transparent and capable of effectively communicating their uncertainties.

My work on overconfidence not only contributed to understanding biases in human-AI interactions but also fueled my interest in refining AI frameworks to align more closely with human expectations and ethical standards. This research continues to motivate me to explore new avenues in human-AI collaboration and the responsible deployment of AI technologies.
