---
permalink: /
title: "Story about where I start my journey"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Previously, I collaborated on a UW ischool capstone project EVAN9000 with team InfVision, leverages open-source large language models (LLMs) to democratize access to advanced digital tools, especially targeting underprivileged organizations and small businesses. The project aims to break down technological barriers that typically exclude smaller entities from benefitting from AI advancements monopolized by larger enterprises. By focusing on the scalability of open-source models and local customization, it offers a cost-effective way to enhance operational efficiency, empowering these organizations to compete more effectively and innovate within their sectors. This project triggered my passion for research, inspiring me to delve deeper into the possibilities of using AI to promote inclusivity and digital equity. Seeing firsthand how technological gaps can limit innovation for smaller entities, I became driven to explore solutions that bridge these divides. Working on EVAN9000 made me realize the potential of open-source LLMs to democratize digital access and empower underprivileged organizations. This experience reinforced my desire to contribute to research initiatives that explore scalable AI solutions, fostering equitable access and sustainable growth for all communities.


Getting started Research
======
In my overconfidence research project, I focused on exploring the psychological and cognitive aspects of overconfidence in humans and comparing them with similar patterns observed in AI systems. The goal was to examine how individuals and AI models assess their own knowledge and decision-making accuracy, especially in contexts involving complex problem-solving or ambiguous information.

Guided by Professor Howe, this project involved designing and conducting a series of experiments to study human confidence levels in relation to task difficulty. We measured participantsâ€™ self-assessments of their performance and compared these with their actual accuracy to quantify overconfidence biases. My analysis revealed notable trends in human overconfidence, such as the tendency to overestimate accuracy in easier tasks and underestimate it in more challenging ones.

Building on these insights, I extended the research to large language models (LLMs) to evaluate their confidence calibration. By incorporating varying types of prompts, expertise levels, and difficulty levels, I was able to observe patterns of LLM confidence behavior that mimicked or diverged from human tendencies. For instance, I found that while LLMs displayed consistent confidence in familiar domains, their calibration varied significantly when dealing with novel or ambiguous tasks.

This comparative analysis of humans and AI underscored the importance of developing better calibration techniques to improve the reliability and trustworthiness of AI systems in decision-making scenarios. Moreover, it highlighted the need for an ethical approach in designing AI models, ensuring they are transparent and capable of communicating their uncertainties effectively.

My work on overconfidence not only contributed to understanding biases in human-AI interactions but also fueled my interest in refining AI frameworks to align more closely with human expectations and ethical standards. This research continues to motivate me to explore new avenues in human-AI collaboration and the responsible deployment of AI technologies.
